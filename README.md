# Localinsight

-someone build a streamlit front end plz

--for that just tinker with app.py

--allow users to select what model they want to use so for that use `import ollama` not langchain ollama you can find documentation for that here 'https://github.com/ollama/ollama-python'. like `ollama.list()` 

--also maybe allow users to set their file path+

- maybe add auido support using transcription if you have time
-requirements.txt is bloated 
-